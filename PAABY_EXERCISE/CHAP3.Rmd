---
title: "chap 3"
author: "Laura W. Paaby"
date: "2/7/2022"
output: html_document
---

## SAMPLING FROM A GRID APPROXIMATE POSTERIOR 
making the posterior for the globe tossing model (tossing a globe to see if it hits either water or land):

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) 
prob_p <- rep( 1 , 1000 )
prob_data <- dbinom( 6 , size=9 , prob=p_grid )
posterior <- prob_data * prob_p
posterior <- posterior / sum(posterior)
```

Now lets draw 10,000 samples from this posterior -> the posterior is a bucket full of parameter values

```{r}
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE) #size is here the amount of samples you draw - the higher the value the closer will it be to ideal - and the longer itll take
plot(samples)
```

```{r}
library(rethinking)
dens( samples )
```
# INTERVALS AND DEFINED BOUNDARIES 
in a simple grid approximation to find where the proportion of water is less than 0.5. (remember the globe toss) => this is done by adding up all places where the parameter values in the grid is below 0.5:
```{r}
#  add up posterior probability where p < 0.5 
sum( posterior[ p_grid < 0.5 ] )
```

So 17% of the posterior probability is below 0.5. 

Now the same can be achived without using the grid - which is often inadequate in more complex situation - we are now taking where samples are less then 0.5 divided by the number of samples drawn. 
```{r}
 sum( samples < 0.5 ) / 1e4
```

##### posteriors between 0.5 and 0.75:
```{r}
 sum( samples > 0.5 & samples < 0.75 ) / 1e4
```


done directly from posterior we can find the lower 80% posterior probability:
```{r}
quantile(samples, 0.8)
```

boundaries htat also can be found by:
```{r}
quantile( samples , c( 0.1 , 0.9 ) )
```






### PERCENTILE INTERVAL
```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) 
prior <- rep(1,1000)
likelihood <- dbinom( 3 , size=3 , prob=p_grid ) 
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
samples <- sample( p_grid , size=1e4 , replace=TRUE , prob=posterior )
```


computing the 50% PERCENTILE COMPATIBILITY INTERVAL 
```{r}
rethinking::PI(samples, prob = 0.5)
```

This interval assigns 25% of the probability mass above and below the interval. So it pro- vides the central 50% probability.

THIS KIND OF DOES NOT WORK IF DATA IS SUPER SCEWED - INSTEAD LOOK AT *HIGHEST POSTERIOR DENSITY INTERVAL* => HPDO

```{r}
rethinking::HPDI(samples, prob = 0.5)
```

HOWEVER:When the posterior is bell shaped, it hardly matters which type of interval you use



# PRODUCE POINT ESTIMATES
there are different kinds and often should you not do it if you dont have any good reason, but here are some to go by:

#### the mamiximum posteriori - the higest posterior probability
```{r}
p_grid[which.max(posterior)]

## can also be done by
rethinking::chainmode( samples , adj=0.01 )
```
in this case it is a 100% or very close to

other points are median/mwan;
```{r}
mean(samples)
median(samples)
```



